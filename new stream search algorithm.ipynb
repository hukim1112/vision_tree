{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/home/files/vision_tree\")\n",
    "from utils.session_config import setup_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "setup_gpus(memory_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense, ReLU, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17609, 28, 28, 1)\n",
      "(17609,)\n"
     ]
    }
   ],
   "source": [
    "data_0 = np.load(\"/home/files/datasets/mnist/0.npy\")\n",
    "label_0 = np.zeros(len(data_0), np.int32)\n",
    "data_5 = np.load(\"/home/files/datasets/mnist/5.npy\")\n",
    "label_5 = np.ones(len(data_5), np.int32)\n",
    "data_7 = np.load(\"/home/files/datasets/mnist/7.npy\")\n",
    "label_7 = np.ones(len(data_7), np.int32)*2\n",
    "\n",
    "train_x = tf.concat([data_0, data_5, data_7], axis=0)\n",
    "train_x = tf.cast(train_x, tf.float32)\n",
    "train_x = train_x[:,:,:,tf.newaxis]/255.\n",
    "train_y = tf.concat([label_0, label_5, label_7], axis=0)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "x = tf.data.Dataset.from_tensor_slices(train_x)\n",
    "y = tf.data.Dataset.from_tensor_slices(train_y)\n",
    "ds = tf.data.Dataset.zip((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ds.take(100).batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 layer name :  conv2d_3\n",
      "Conv2D\n",
      "0 layer name :  re_lu_3\n",
      "0 layer name :  max_pooling2d_2\n",
      "2 layer name :  conv2d_4\n",
      "Conv2D\n",
      "0 layer name :  re_lu_4\n",
      "0 layer name :  max_pooling2d_3\n",
      "2 layer name :  conv2d_5\n",
      "Conv2D\n",
      "0 layer name :  re_lu_5\n",
      "0 layer name :  global_average_pooling2d_1\n",
      "2 layer name :  dense_1\n",
      "Dense\n"
     ]
    }
   ],
   "source": [
    "#test1\n",
    "from utils.BEP import Back_etching_propagation\n",
    "trained_model = tf.keras.models.load_model(\"/home/files/vision_tree/train/ckpt/mnist_cnn/057.h5\")\n",
    "bep_algorithm = Back_etching_propagation(trained_model)\n",
    "#etching start\n",
    "#bep_algorithm.categorical_etching(ds, num_class=3, save_path='057')\n",
    "\n",
    "test1 = bep_algorithm.model\n",
    "\n",
    "idx = 12\n",
    "model = test1\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[idx].trainable = True #turn on the target etching layer.\n",
    "y = Input(shape=(), dtype=tf.int32)\n",
    "i = model.layers[idx].output\n",
    "_,o = model.layers[idx+1](i)\n",
    "\n",
    "etching_model = tf.keras.Model(inputs=[model.input,y], outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 28, 28, 1, 1 0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "etching__layer_8 (Etching_Layer (None, 28, 28, 1, 16 16          tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "functional_23 (Functional)      [(None, 26, 26, 16), 160         etching__layer_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 26, 26, 16)   0           functional_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 16)   0           re_lu_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 13, 13, 16,  0           max_pooling2d_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "etching__layer_9 (Etching_Layer (None, 13, 13, 16, 1 256         tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "functional_25 (Functional)      [(None, 11, 11, 16), 2320        etching__layer_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 11, 11, 16)   0           functional_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 16)     0           re_lu_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 5, 5, 16, 1) 0           max_pooling2d_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "etching__layer_10 (Etching_Laye (None, 5, 5, 16, 16) 256         tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_27 (Functional)      [(None, 3, 3, 16), ( 2320        etching__layer_10[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 5,328\n",
      "Trainable params: 256\n",
      "Non-trainable params: 5,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "etching_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "12\n",
      "7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for L,idx in enumerate(bep_algorithm.etching_layer_indice[::-1]):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.BEP.Etching_Layer at 0x7fc8c40b3be0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etching_model.layers[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1E-3)\n",
    "for x,y in test_set:\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = etching_model([x,y], training=True)\n",
    "        loss = tf.reduce_mean(pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.]], dtype=float32)]\n",
      "[array([[1.0000094 , 0.99973005, 0.99949145, 1.0002098 , 0.9996077 ,\n",
      "        1.        , 0.9999939 , 0.9995063 , 1.0001489 , 0.99933636,\n",
      "        1.0000232 , 0.99992126, 0.9996089 , 0.9993713 , 0.99991655,\n",
      "        0.9999421 ],\n",
      "       [0.9999788 , 0.99995524, 0.99995714, 1.0000026 , 1.0000601 ,\n",
      "        1.        , 1.0000714 , 0.9999181 , 1.0000172 , 0.999977  ,\n",
      "        0.9999847 , 0.9999682 , 0.9999601 , 0.9999933 , 0.9999649 ,\n",
      "        0.9999798 ],\n",
      "       [0.9997662 , 0.9996923 , 0.9999578 , 0.9996152 , 1.0000083 ,\n",
      "        1.        , 1.0001248 , 0.9997399 , 0.999995  , 1.0000896 ,\n",
      "        0.999904  , 0.99979126, 0.9999206 , 1.0001749 , 0.99969035,\n",
      "        1.0002458 ],\n",
      "       [1.0000362 , 1.0000196 , 0.99984866, 1.0000182 , 0.9999394 ,\n",
      "        1.        , 0.9999433 , 1.0001312 , 1.0000261 , 0.9998075 ,\n",
      "        0.9998524 , 1.0000379 , 1.0000207 , 0.99986583, 1.0000876 ,\n",
      "        0.9999215 ],\n",
      "       [1.0001618 , 0.9999246 , 0.9998074 , 1.0001961 , 1.0000049 ,\n",
      "        1.        , 1.0002198 , 0.9997314 , 1.0003375 , 0.9997191 ,\n",
      "        0.9998919 , 0.9998605 , 0.9998354 , 0.99997187, 0.9998125 ,\n",
      "        0.9996444 ],\n",
      "       [1.0000234 , 1.0000911 , 1.0000131 , 0.99969816, 0.99949044,\n",
      "        1.        , 0.99962366, 1.0000461 , 0.999503  , 0.9996861 ,\n",
      "        0.999826  , 1.0001594 , 1.0000507 , 0.9997253 , 0.99969846,\n",
      "        0.99971104],\n",
      "       [0.99994   , 1.000016  , 0.9998404 , 1.000096  , 0.9998442 ,\n",
      "        1.        , 0.99985427, 0.99978274, 1.0002794 , 0.9998952 ,\n",
      "        0.9998759 , 0.9998863 , 0.999845  , 0.9997261 , 1.0000446 ,\n",
      "        0.99988556],\n",
      "       [0.9997975 , 0.99987173, 1.0000049 , 0.9996344 , 0.99968195,\n",
      "        1.        , 0.99991447, 1.0000004 , 0.99957216, 0.99993277,\n",
      "        0.9998589 , 0.9998596 , 0.9999306 , 0.99977446, 1.0002637 ,\n",
      "        0.99991256],\n",
      "       [0.99998236, 1.0001793 , 0.9999629 , 0.9999055 , 0.9999709 ,\n",
      "        1.        , 0.9996755 , 1.0000298 , 0.99986535, 0.9998771 ,\n",
      "        0.99997723, 1.0000682 , 1.0000536 , 0.9999662 , 0.9999898 ,\n",
      "        0.9999091 ],\n",
      "       [0.99989206, 1.0000017 , 0.9996529 , 0.99994975, 0.99988097,\n",
      "        1.        , 0.99992824, 0.99995065, 0.9998363 , 0.9999069 ,\n",
      "        1.0000166 , 0.99991506, 0.99996114, 0.9996352 , 1.0000004 ,\n",
      "        1.0000404 ],\n",
      "       [0.9999657 , 0.9999217 , 0.9997381 , 0.99995416, 1.0001881 ,\n",
      "        1.        , 0.99991727, 0.99990267, 0.99980634, 0.999859  ,\n",
      "        1.000046  , 0.9999378 , 0.99982363, 0.99975586, 0.9998832 ,\n",
      "        0.9999158 ],\n",
      "       [0.99982697, 0.9999939 , 0.9999928 , 0.9998833 , 0.99962825,\n",
      "        1.        , 0.9997072 , 0.99984616, 0.9995738 , 0.99989504,\n",
      "        0.9998517 , 1.0000463 , 0.9999112 , 1.0003471 , 0.999796  ,\n",
      "        1.0000595 ],\n",
      "       [0.99998635, 1.0000836 , 0.9999085 , 0.99915683, 0.99980795,\n",
      "        1.        , 0.9996902 , 1.0001597 , 0.9995553 , 1.0004954 ,\n",
      "        0.999921  , 1.0001521 , 0.99994135, 1.0002201 , 1.0001811 ,\n",
      "        0.9999079 ],\n",
      "       [0.999926  , 1.0000159 , 1.000048  , 0.99970937, 0.9998876 ,\n",
      "        1.        , 0.99981546, 1.0001009 , 0.99965906, 1.000106  ,\n",
      "        1.000112  , 1.00009   , 1.0001589 , 1.0003146 , 0.9997207 ,\n",
      "        1.0000424 ],\n",
      "       [1.0000442 , 0.9999074 , 1.0000015 , 0.99996585, 0.9999031 ,\n",
      "        1.        , 0.9998094 , 0.9999663 , 0.9998614 , 0.9998765 ,\n",
      "        0.99983406, 0.99990255, 0.9998568 , 0.99996835, 0.99993813,\n",
      "        0.9999488 ],\n",
      "       [1.0001247 , 0.9998717 , 0.9998068 , 1.0000896 , 0.99998605,\n",
      "        1.        , 1.0000669 , 0.9998616 , 1.0001894 , 0.9999647 ,\n",
      "        1.000023  , 0.99984926, 0.9997474 , 0.9997559 , 0.9999335 ,\n",
      "        0.9998872 ]], dtype=float32)]\n",
      "[array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "      dtype=float32)]\n",
      "[array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for L,idx in enumerate(bep_algorithm.etching_layer_indice[::-1]):\n",
    "    print(model.layers[idx].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.0000094 , 0.99973005, 0.99949145, 1.0002098 , 0.9996077 ,\n",
       "         1.        , 0.9999939 , 0.9995063 , 1.0001489 , 0.99933636,\n",
       "         1.0000232 , 0.99992126, 0.9996089 , 0.9993713 , 0.99991655,\n",
       "         0.9999421 ],\n",
       "        [0.9999788 , 0.99995524, 0.99995714, 1.0000026 , 1.0000601 ,\n",
       "         1.        , 1.0000714 , 0.9999181 , 1.0000172 , 0.999977  ,\n",
       "         0.9999847 , 0.9999682 , 0.9999601 , 0.9999933 , 0.9999649 ,\n",
       "         0.9999798 ],\n",
       "        [0.9997662 , 0.9996923 , 0.9999578 , 0.9996152 , 1.0000083 ,\n",
       "         1.        , 1.0001248 , 0.9997399 , 0.999995  , 1.0000896 ,\n",
       "         0.999904  , 0.99979126, 0.9999206 , 1.0001749 , 0.99969035,\n",
       "         1.0002458 ],\n",
       "        [1.0000362 , 1.0000196 , 0.99984866, 1.0000182 , 0.9999394 ,\n",
       "         1.        , 0.9999433 , 1.0001312 , 1.0000261 , 0.9998075 ,\n",
       "         0.9998524 , 1.0000379 , 1.0000207 , 0.99986583, 1.0000876 ,\n",
       "         0.9999215 ],\n",
       "        [1.0001618 , 0.9999246 , 0.9998074 , 1.0001961 , 1.0000049 ,\n",
       "         1.        , 1.0002198 , 0.9997314 , 1.0003375 , 0.9997191 ,\n",
       "         0.9998919 , 0.9998605 , 0.9998354 , 0.99997187, 0.9998125 ,\n",
       "         0.9996444 ],\n",
       "        [1.0000234 , 1.0000911 , 1.0000131 , 0.99969816, 0.99949044,\n",
       "         1.        , 0.99962366, 1.0000461 , 0.999503  , 0.9996861 ,\n",
       "         0.999826  , 1.0001594 , 1.0000507 , 0.9997253 , 0.99969846,\n",
       "         0.99971104],\n",
       "        [0.99994   , 1.000016  , 0.9998404 , 1.000096  , 0.9998442 ,\n",
       "         1.        , 0.99985427, 0.99978274, 1.0002794 , 0.9998952 ,\n",
       "         0.9998759 , 0.9998863 , 0.999845  , 0.9997261 , 1.0000446 ,\n",
       "         0.99988556],\n",
       "        [0.9997975 , 0.99987173, 1.0000049 , 0.9996344 , 0.99968195,\n",
       "         1.        , 0.99991447, 1.0000004 , 0.99957216, 0.99993277,\n",
       "         0.9998589 , 0.9998596 , 0.9999306 , 0.99977446, 1.0002637 ,\n",
       "         0.99991256],\n",
       "        [0.99998236, 1.0001793 , 0.9999629 , 0.9999055 , 0.9999709 ,\n",
       "         1.        , 0.9996755 , 1.0000298 , 0.99986535, 0.9998771 ,\n",
       "         0.99997723, 1.0000682 , 1.0000536 , 0.9999662 , 0.9999898 ,\n",
       "         0.9999091 ],\n",
       "        [0.99989206, 1.0000017 , 0.9996529 , 0.99994975, 0.99988097,\n",
       "         1.        , 0.99992824, 0.99995065, 0.9998363 , 0.9999069 ,\n",
       "         1.0000166 , 0.99991506, 0.99996114, 0.9996352 , 1.0000004 ,\n",
       "         1.0000404 ],\n",
       "        [0.9999657 , 0.9999217 , 0.9997381 , 0.99995416, 1.0001881 ,\n",
       "         1.        , 0.99991727, 0.99990267, 0.99980634, 0.999859  ,\n",
       "         1.000046  , 0.9999378 , 0.99982363, 0.99975586, 0.9998832 ,\n",
       "         0.9999158 ],\n",
       "        [0.99982697, 0.9999939 , 0.9999928 , 0.9998833 , 0.99962825,\n",
       "         1.        , 0.9997072 , 0.99984616, 0.9995738 , 0.99989504,\n",
       "         0.9998517 , 1.0000463 , 0.9999112 , 1.0003471 , 0.999796  ,\n",
       "         1.0000595 ],\n",
       "        [0.99998635, 1.0000836 , 0.9999085 , 0.99915683, 0.99980795,\n",
       "         1.        , 0.9996902 , 1.0001597 , 0.9995553 , 1.0004954 ,\n",
       "         0.999921  , 1.0001521 , 0.99994135, 1.0002201 , 1.0001811 ,\n",
       "         0.9999079 ],\n",
       "        [0.999926  , 1.0000159 , 1.000048  , 0.99970937, 0.9998876 ,\n",
       "         1.        , 0.99981546, 1.0001009 , 0.99965906, 1.000106  ,\n",
       "         1.000112  , 1.00009   , 1.0001589 , 1.0003146 , 0.9997207 ,\n",
       "         1.0000424 ],\n",
       "        [1.0000442 , 0.9999074 , 1.0000015 , 0.99996585, 0.9999031 ,\n",
       "         1.        , 0.9998094 , 0.9999663 , 0.9998614 , 0.9998765 ,\n",
       "         0.99983406, 0.99990255, 0.9998568 , 0.99996835, 0.99993813,\n",
       "         0.9999488 ],\n",
       "        [1.0001247 , 0.9998717 , 0.9998068 , 1.0000896 , 0.99998605,\n",
       "         1.        , 1.0000669 , 0.9998616 , 1.0001894 , 0.9999647 ,\n",
       "         1.000023  , 0.99984926, 0.9997474 , 0.9997559 , 0.9999335 ,\n",
       "         0.9998872 ]], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[12].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,851\n",
      "Trainable params: 4,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#test2\n",
    "test2 = tf.keras.models.load_model(\"/home/files/vision_tree/train/ckpt/mnist_cnn/057.h5\")\n",
    "test2.summary()\n",
    "activation_idx = [4, 7]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etching_model = tf.keras.Model(inputs=[model.input,y], outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for L,idx in enumerate(self.etching_layer_indice[::-1]):\n",
    "            print(idx)\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = False\n",
    "            self.model.layers[idx].trainable = True #turn on the target etching layer.\n",
    "            y = Input(shape=(), dtype=tf.int32)\n",
    "            i = self.model.layers[idx].output\n",
    "            _,o = self.model.layers[idx+1](i)\n",
    "            if L == 0: #classification feature\n",
    "                o = o*tf.one_hot(y, depth=num_class)\n",
    "                etching_model = tf.keras.Model(inputs=[self.model.input,y], outputs=o)\n",
    "            else:\n",
    "                etching_model = tf.keras.Model(inputs=[self.model.input,y], outputs=o)\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=1E-3)\n",
    "            for x,y in ds:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    pred = etching_model([x,y], training=True)\n",
    "                    loss = tf.reduce_mean(pred)\n",
    "                gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "            etching_weights = self.model.layers[idx].get_weights()[0]\n",
    "            np.save(\"{}/{}.npy\".format(save_path, len(self.etching_layer_indice)-L-1), etching_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
